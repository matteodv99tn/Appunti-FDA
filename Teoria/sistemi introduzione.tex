\chapter{Automatica e sistemi}

	\begin{concetto}
		\textit{L'\textbf{automatica} è la disciplina che studia come agire su un sistema in modo che il suo comportamento assomigli a quello desiderato, senza necessità  di intervento manuale}.
	\end{concetto}
	Di fatto lo scopo di questo corso è quello di capire come un sistema da controllare si comporta e studiare un opportuno controllore in grado da fornire dei risultati accettabili.
	
\section{Sistema di controllo}
	\subsection{Sistema}
	
		\begin{concetto}
			L'automatica si basa sullo studio di \textbf{sistemi}, ossia un insieme di elementi fisici o concettuali il cui comportamento cambia nel tempo e/o spazio e che interagiscono con il mondo circostante. I sistemi, come mostrati in figura \ref{sistema}, sono modellati come delle \textit{black box} le cui interazioni con l'ambiente esterno sono rappresentate dai rami, ossia le frecce entranti/uscenti: in particolare si osservano
			\begin{itemize}
			    \item gli \textbf{ingressi di controllo}  $u$ (o semplicemente \textbf{ingressi}) i valori in ingresso al sistema che potranno essere modificati a piacimento dal controllore;
			    \item gli \textbf{ingressi di disturbo} $d$, ossia valori la cui evoluzione non può essere influenzata e in generale dei quali non è conosciuto l'andamento;
			    \item le \textbf{uscite} $y$ del sistema che descrivono la sua evoluzione e che dunque possono influenzare l'ambiente con il quale interagiscono.
			\end{itemize}
		\end{concetto}

    	\figuratikz{4}{1}{sistema}{schema di un sistema.}{sistema}
    	
    	In molti casi la scelta di catalogare una variabile come ingresso o uscita è puramente arbitraria e deve essere contestualizzata al problema da risolvere. Considerando l'esempio di un'automobile, la coppia motrice può essere considerata come un'uscita se si considera che essa derivata dal motore che si interfaccia sul veicolo e che è determinata da ingressi quali la quantità di carburante, temperatura dell'aria ecc. Tuttavia la stessa coppia motrice può anche essere considerata come un ingresso che l'automobile utilizza per seguire la sua traiettoria.
    	
    \subsection{Controllo}
        \begin{concetto}
                Il \textbf{controllore} è la \textit{black box} che rappresenta il controllo automatico, ossia che descrive l'azione che deve essere applicata al sistema per farlo evolvere come desiderato. Il controllore, mostrato in figura \ref{controllore}, è del tutto similare come rappresentazione ad un sistema, dove tuttavia come rami in ingresso si osserva la \textbf{specifica del problema} $\overline y$, ossia il valore di \textbf{riferimento} al quale deve tendere a regime il sistema, mentre in uscita si ha l'\textbf{azione di controllo} $u$ del controllore $C$ sul sistema $S$. Altri ingressi sono connotati generalmente dalla variabile $i$.
         \end{concetto}
    	
    	\figuratikz{4}{1}{controllo}{schema di un controllore.}{controllore}
    	
    	Idealmente la \textbf{variabile controllata} (ossia l'uscita $y$ del sistema $S$) deve essere pari al segnale di riferimento $\overline y$ in ogni condizione, ossia indipendentemente dal rumore $n$ e dai disturbi $d$ che agiscono sull'insieme di controllore e sistema. Tuttavia per modellare più \textit{correttamente} l'andamento reale in generale l'obbiettivo del controllo è quello di minimizzare l'errore $e$ del sistema:
    	\begin{equation}
    	    \underbrace{\textrm{errore}}_e = \underbrace{\textrm{valore di riferimento}}_{\overline y} - \underbrace{\textrm{variabile controllata}}_y
    	\end{equation}
    	
    	Spesso i limiti delle specifiche di controllo sono limitate dalla grandezza della variabile di controllo stessa: per esempio una Fiat non potrà mai accelerare come una Ferrari per via del motore che è implementato sulla stessa.
    	
    \subsection{Sistema di controllo}
        \begin{concetto}
            Un opportuno collegamento tra controllore $C$ e sistema $S$ determina dunque il \textbf{sistema di controllo} (figura \ref{fig:sis:anelli}); questo nuovo sistema contiene praticamente tutti gli elementi fin'ora visti, ossia in particolare il valore di riferimento $\overline y$, la variabile di controllo $u$ che si interfaccia sul sistema e l'uscita $y$ del sistema, ossia la \textbf{variabile da controllare}.
            
            E' inoltre possibile classificare i sistemi di controllo in base alla topologia degli stessi, in particolare si parla di \textbf{anello aperto} quando le uscite del sistema $y$ non sono poste in retroazione alla variabile di riferimento, mentre quando ciò avviene si parla di controllo in \textbf{anello chiuso}.
        \end{concetto}
        
        \begin{figure}[bht]
        	\centering 
        	\begin{subfigure}{0.48\linewidth}
        		\centering
        		\resizebox{0.98\linewidth}{!}{\tikzfig{Immagini/sistema-controllo-a}} \caption{}
        	\end{subfigure}
	        \begin{subfigure}{0.48\linewidth}
		        \centering
		        \resizebox{0.98\linewidth}{!}{\tikzfig{Immagini/sistema-controllo-b}} \caption{}
		    \end{subfigure}
	    	\caption{esempio di sistema di controllo in anello aperto (a) e in anello chiuso (b).}
	    	\label{fig:sis:anelli}
        \end{figure}
            	
        Come si osserverà un sistema in anello aperto per poter funzionare \textit{correttamente} deve conoscere perfettamente il funzionamento del sistema e i parametri dello stesso, mentre un sistema in anello chiuso, seppur più complesso (in quanto prevede il montaggio di sensori e algoritmo di controllo più sofisticati), permette di ottenere prestazioni sensibilmente \textit{migliori}, immuni da incertezze e interferenze esterne.
    	
    	\begin{concetto}
    		Il \textbf{problema di controllo} è quello dunque di determinare le variabili di controllo $u$ affinché le variabili da controllare siano simili al segnale di riferimento per ogni possibile \textit{traiettoria} del riferimento $\overline y$ e dei disturbi $d$:
    		\[ y\simeq \overline y \]
    	\end{concetto}
    
\section{Classificazione dei sistemi}
	Come fin'ora visto, i sistemi (e i controlli) possono essere assimilati a delle black box caratterizzate dagli ingressi $u$ e le uscite $y$. In un sistema è possibile individuare sia deii \textbf{parametri}, ossia delle quantità che descrivono la struttura e le proprietà del sistema (come la massa o la geometria di un corpo) che tendenzialmente sono tempo-invarianti, sia delle \textbf{variabili}, ossia delle grandezze che descrivono l'evoluzione nel tempo del sistema (come posizione e velocità del corpo).
	
	A questo punto è dunque fondamentale \textbf{classificare} i vari sistemi nei cosiddetti \textit{\textbf{assi di classificazione}}, ossia una serie di connotazioni non esclusive che permettono di categorizzare i vari tipi di sistemi.
	
	\subsubsection{MIMO e SISO}
		Questo asse di classificazione è caratterizzato dagli acronimi \textit{Multi-Input Multi-Output} MIMO e \textit{Single-Input Single-Output} SISO; come si può evincere dalla traduzione dall'inglese, un sistema MIMO presenta un numero multiplo sia di ingressi $u$ che di uscite $y$ e dunque tali valori possono essere rappresentati da un vettore. Al contrario un sistema SISO presenta un solo valore in ingresso $u$ e un'uscita $y$, e dunque possono essere descritti solamente da un valore scalare.
		
		In particolare le $n$ uscite di un sistema MIMO sono collegate agli $m$ ingressi dello stesso secondo delle relazioni funzionali $f_i$ secondo che possono essere espresse come
		\begin{align*}
			y_1 & = f_1\big(u_1, u_2,\dots, u_m\big) \\
			y_2 & = f_2\big(u_1, u_2,\dots, u_m\big) \\
			& \ \vdots \\
			y_n & = f_n\big(u_1, u_2,\dots, u_m\big) 
		\end{align*}
	
	\subsubsection{Sistemi lineari e non lineari}
		Un \textbf{sistema} è detto \textbf{lineare} se rispetta le condizioni di linearità tra ingresso e uscita, ossia se nota l'uscita $f(u_1), f(u_2)$ per due ingressi noti $u_1,u_2$, allora l'uscita $f(u)$ di un ingresso ottenuto come combinazione lineare di $u_1,u_2$ deve essere la stessa combinazione lineare delle due uscite; in termini matematici una funzione per essere lineare deve essere tale che
		\[ u = \alpha_1 u_1 + \alpha_2 u_2 \qquad \Rightarrow \quad f(u) = \alpha_1 f(u_1) + \alpha_2 f(u_2) \]
    	Ogni qualvolta questa condizione non venisse rispettata, il \textbf{sistema} è semplicemente detto \textbf{non lineare}.
    
    	\paragraph{Rappresentazione matriciale per sistemi lineari} In generale un sistema lineare di tipo mimo può essere espresso come un sistema di equazioni lineari del tipo
    	\[\begin{cases}
    		y_1 = k_{11} u_1 + \dots + k_{1m} u_m \\
    		\ \vdots \\ 
    		y_n = k_{n1} u_1 + \dots + k_{nm} u_m
    	\end{cases}\]
    	Per come visto in algebra lineare è altresì possibile convertire tale sistema in \textit{notazione algebrica} in un sistema rappresentato in forma matriciale dal vettore $\boldsymbol u$ degli ingressi e $\boldsymbol y$ delle uscite e dalla matrice dei coefficienti $ K$:
    	\[ \boldsymbol{y} = K \boldsymbol{u} \qquad \leftrightarrow\qquad \begin{pmatrix}
    		y_1 \\ \vdots \\ y_n
    	\end{pmatrix} = \begin{bmatrix}
    		k_{11} & \dots & k_{1m} \\ 
    		\vdots & \ddots \\
    		k_{n1} & & k_{nm}
    	\end{bmatrix} \begin{pmatrix}
    		u_1 \\ \vdots \\ u_m
    	\end{pmatrix}\]
    	\begin{osservazione}
    		In seguito non verrà più rappresentata alcuna differenza tra la rappresentazione degli ingressi $u$ e uscite $y$ come scalari o vettori, in quanto i due comportamenti per sistemi lineari sono analoghi.
    	\end{osservazione}
    	
    \subsubsection{Sistemi a tempo continuo e a tempo discreto}
    	Nei \textbf{sistemi a tempo continuo} le variabili evolvo, per l'appunto, con continuità nel tempo $t$, mentre i \textbf{sistemi a tempo discreto} presentano variabili che mutano solamente in corrispondenza di tempi $k\in \mathds Z$ che possono assumere solamente valori discreti interi.
    	
    	In generale i sistemi a tempo discreto derivano o dall'approssimazione di sistemi a tempo continuo oppure da sistemi dinamici (tendenzialmente concettuali) che nativamente devono prevedere una successione di eventi ad intervalli (come per esempio un algoritmo di calcolo di zeri di funzione tramite il metodo di Newton).
    	
    \subsubsection{Sistemi tempo varianti e tempo invarianti}
    	Sono detti \textbf{sistemi tempo varianti} tutti quei sistemi per cui il funzionale $f$ che lega l'uscita con l'ingresso dipende esplicitamente dal tempo, ossia assume una \textit{forma} del tipo
    	\[  y = f(u,t)\]
    	Un esempio di questo tipo di sistema è dato dalla funzione $f(u,t) = u^2 + 2t$.
    	
    	Al contrario se la funzione $f$ è indipendente dal tempo $t$, allora il \textbf{sistema} è detto \textbf{tempo invariante} ed è rappresentato da una relazione del tipo
    	\[ y = f(u) \]
    	Un esempio di questo tipo di sistema è dato dalla relazione $f(u) = e^u + 2u^3$.
    	
    	\begin{osservazione}
    		La (in)varianza del sistema rispetto al tempo è riferita solamente rispetto al funzionale $f$ che lega in generale l'ingresso con l'uscita, ma non all'ingresso $u$ che può variare nel tempo per stabilire la \textit{dinamica} del sistema!
    	\end{osservazione}
    
   	\subsubsection{Sistemi statici e sistemi dinamici}
   		La distinzione tra sistemi statici e dinamici è la più importante in quanto ci permette di capire meglio come approcciare l'analisi del sistema.
    	
    	\begin{concetto}
    		Un \textbf{sistema} è detto \textbf{statico} se la relazione tra ingresso è uscita è descritta da un'equazione algebrica del tipo $$y=f(u)$$
    		Intuitivamente ciò significa che per determinare l'uscita $y$ ad un istante generico di tempo $t^*$ è sufficiente conoscere il valore dell'ingresso $u^*$ in tale istante: in questo modo la \textit{storia} degli ingressi è ininfluente sulla determinazione dell'uscita e per questo tali sistemi sono detti \textbf{\textit{memory-less}}.
    	\end{concetto}
    	\begin{concetto}
    		Al contrario di quanto appena affermato, sono detti \textbf{sistemi dinamici} tutti quei sistemi rispetto ai quali per determinare il valore dell'uscita $y$ al tempo $t^*$ non è sufficiente conoscere solamente l'ingresso $u(t^*)$, ma anche tutto il pregresso temporale dell'ingresso $u(t)$ nell'intervallo di tempo compreso tra l'origine dei tempi $t_0$ e il tempo in questione $t^*$. Matematicamente questo tipo di sistemi è dunque governato non da un'equazione algebrica ma da un'\textbf{equazione differenziale} (ordinarie).
    		
    		Per questi sistemi sono dette \textbf{variabili di stato}, generalmente indicate come $x$, quelle variabili che occorre conoscere all'istante $t_0$ (insieme alla storia degli ingressi $u(t)$) per determinare univocamente l'uscita $y(t^*)$.
    	\end{concetto}
    
    	\begin{esempio}{: bottiglia che si riempie} \label{es:intro:bottiglia}
    		Si consideri il caso di una bottiglia (approssimata ad un cilindro) nella quale si versa una portata d'acqua $q$ (corrispondente all'ingresso $u$ del sistema) alla quale è associata la quota $h$ di fluido (corrispondente all'uscita del sistema) nella bottiglia stessa.
    		
    		In questo caso la \textbf{variabile di controllo} corrisponde alla portata $q=u$ (ingresso), mentre la \textbf{variabile controllata} è la quota $h = y$.
    		\begin{center}
    			\tikzfig{Immagini/bottiglia}
    		\end{center}
    		Osservando l'andamento dell'ingresso $u$ del sistema (diagramma a sinistra), è possibile osservare come nel tempo il livello del fluido (uscita $y$) vari nel tempo (diagramma a destra).
    		
    		Questo esempio ci permette di capire che il \textbf{sistema} è \textbf{dinamico}; considerando per esempio gli istanti $t_1,t_2$, dal diagramma a sinistra è possibile osservare che gli ingressi sono uguali e pari a zero (non si ha flusso di acqua entrante nella bottiglia), tuttavia il livello di acqua nei due istanti è diverso per via del fatto che nell'intervallo di tempo $[t_a,t_b]$ si ha avuto un flusso di acqua entrante nel sistema che ha cambiato il livello di fluido nella bottiglia.
    	\end{esempio}
    
\section{Spazio di stato e sua rappresentazione} \label{sec:intro:spaziostato}
	\begin{concetto}
		La \textit{metodologia universale} per descrivere i sistemi dinamici è basata sulla \textbf{rappresentazione in spazio di stato} del sistema stesso. Questa metodologia si basa sulla scrittura di una serie di \textbf{equazioni di stato} $f$ che relazionano la derivata prima $\dot x$ di una variabile di stato con le variabili di stato (non derivate), gli ingressi e il tempo secondo delle relazioni del tipo
		\[ \dot x = f( x,u,t)\]
		Per completare la rappresentazione è inoltre necessario scrivere anche le \textbf{trasformazioni d'uscita} $g$ che legano le uscite $y$ con le variabili di stato, gli ingressi e il tempo con una relazione del tipo
		\[ y = g(x,u,t)  \]
	\end{concetto}
	\begin{osservazione}
		Se il sistema prevede $n$ variabili di stato, allora sarà necessario scrivere un numero uguale di equazioni di stato $f_i$, una per ogni variabile. In modo analogo in presenza di $m$ uscite del sistema, sarà necessario determinare altrettante trasformazioni. Il tutto si basa sul fatto che $u,x,y$ possono rappresentare dei vettori ma anche degli scalari.
	\end{osservazione}
	Noto il numero $n$ di equazioni differenziali che è possibile individuare in un sistema dinamico, allora tale numero prende il nome di \textbf{ordine del sistema} e rappresenta il numero di variabili di stato $x$ che devono essere utilizzate nell'analisi per descrivere completamente il sistema stesso.
	
	\begin{esempio}{: rappresentazione in spazio di stato} \label{es:intro:bottiglia-2}
		Facendo riferimento all'esempio \ref{es:intro:bottiglia} della bottiglia che si riempie, è possibile creare un modello matematico del sistema. Nota infatti l'area $A$ della base del cilindro, l'altezza $h$ del fluido (coincidente con l'uscita del sistema) e la densità $\rho$ dello stesso allora è possibile calcolare la quantità di acqua presente nel contenitore come
		\[ Q = \rho A h\]
		La portata $q(t)$ di fluido immesso nella bottiglia (ossia l'ingresso del nostro sistema) di fatto determina una variazione di quantità $Q$ di fluido secondo una relazione differenziale che permette di ricavare la variazione dell'uscita in funzione dell'ingresso:
		\[ \frac {dQ}{dt}=q \qquad \xrightarrow{Q = \rho A h}\quad \rho A\dot h = q \qquad \Rightarrow \quad \dot h = \frac 1{\rho A} q \]
		
		Determinata dunque l'equazione differenziale caratteristica del problema è possibile osservare che l'ingresso $u$ è associato alla portata in ingresso $q$, mentre sia variabile di stato $x$ che uscita del sistema $y$ sono associate alla quota $h$ del fluido. In questo caso è possibile \textbf{classificare il sistema} come dinamico (per via dell'equazione differenziale) di ordine $n=1$, SISO, lineare (rispetto a ingresso/uscita/variabili di stato) tempo invariante la cui rappresentazione in forma di stato è data dal sistema:
		\[ \begin{cases}
			\dot h = \dot x = \dfrac 1 {\rho A} q` = \dfrac 1 {\rho A} u \qquad & \textrm{: equazione di stato} \\
			h = y = x & \textrm{: trasformazione d'uscita} \\
		\end{cases} \]
		
	\end{esempio}
	
	\subsection{Rappresentazione matriciale per sistemi lineari} Come osservato in precedenza, i sistemi lineari possono essere espressi come combinazione lineare di opportuni coefficienti; in particolare è possibile riscrivere il sistema di equazioni di stato e delle trasformazioni d'uscita come:
	\begin{equation}
	\begin{aligned}
		\textrm{equazioni di stato:} \qquad & \begin{cases}
			\dot x_1 & = a_{11} x_1 + \dots + a_{1n}x_n + b_{11}u_1 + \dots + b_{1m}u_m \\
			& \ \vdots \\
			\dot x_n & = a_{n1} x_1 + \dots + a_{nn}x_n + b_{n1}u_1 + \dots + b_{nm}u_m \\
		\end{cases} \\
		\textrm{trasformazioni d'uscita:} \qquad & \begin{cases}
		\dot y_1 & = c_{11} x_1 + \dots + c_{1n}x_n + d_{11}u_1 + \dots + d_{1m}u_m \\
		& \ \vdots \\
		\dot y_p & = c_{p1} x_1 + \dots + c_{pn}x_n + d_{p1}u_1 + \dots + d_{pm}u_m \\
		\end{cases}
	\end{aligned}
	\end{equation}
	A questo punto, noto l'ordine $n$ del sistema, il numero $m$ degli ingressi e il numero $p$ delle uscite è possibile riscrivere i sistemi dinamici lineari tramite una rappresentazione matriciale che utilizza le matrici $A\in \mathds R^{n\times n}$, $B\in \mathds R^{n\times m}$, $C\in \mathds R^{p\times n }$ e $D\in \mathds R^{p\times m}$ secondo le espressioni
	\begin{equation} \label{eq:rapp-matriciale}
	\begin{aligned}
		\textrm{equazioni di stato:} & \qquad \dot x = Ax + Bu \\
		\textrm{trasformazioni d'uscita:} & \qquad y = Cx + Du
	\end{aligned}
	\end{equation}
	Rispetto a tale notazione la matrice $A$, che si osserva essere sempre quadrata, prende il nome di \textbf{matrice di stato}.
	
	
	\paragraph{Sistemi dinamici propri e strettamente propri} All'interno dei sistemi dinamici è possibile individuare delle \textit{sotto-categorie} (figura \ref{fig:classificazionesistemi}) individuate dai:
	\begin{itemize}
		\item sistemi dinamici \textbf{strettamente propri}, ossia i sistemi il cui è assente un collegamento diretto tra azione e uscita (per sistemi lineari ciò significherebbe che la matrice $D$ sarebbe nulla);
		\item sistemi dinamici \textbf{propri}, ossia i sistemi in cui l'uscita è anche funzione diretta degli ingressi $u$ (matrice $D$ non nulla per sistemi lineari).
	\end{itemize}
	
	\begin{figure}[bht]
		\centering
		\begin{subfigure}{0.3\linewidth}
			\centering
			\tikzfig{Immagini/strettamente} \caption{}
		\end{subfigure}
		\begin{subfigure}{0.3\linewidth}
			\centering
			\tikzfig{Immagini/nonstrettamente} \caption{}
		\end{subfigure}
		\begin{subfigure}{0.3\linewidth}
			\centering
			\tikzfig{Immagini/statico} \caption{}
		\end{subfigure}
		\caption{black box di un sistema strettamente proprio $(a)$, non strettamente proprio $(b)$ e statico $(c)$.} 
		\label{fig:classificazionesistemi}
	\end{figure}
	
	Secondo questa logica è possibile catalogare i sistemi statici come una sotto-classe di sistemi dinamici dove la trasformazione d'uscita non contiene alcuna variabile di stato $x$.
	
	Facendo riferimento al sistema dinamico dell'esempio \ref{es:intro:bottiglia-2}, esso risulta essere strettamente proprio in quanto l'uscita $y$ dipende solamente dalla variabile di stato $x$.
	
	\subsection{Metodo generale per la determinazione delle equazioni di stato} \label{sec:intro:metodogenerale}
		A questo punto è lecito chiedersi come determinare, in maniera del tutto generale, le equazioni di stato del problema che si vuole analizzare. Data dunque l'equazione differenziale (o il sistema di equazioni differenziali) che governa il sistema dinamico da analizzare è possibile arrivare a determinare le $n$ equazioni di stato (ossia di numero coincidente all'ordine del sistema) effettuando i seguenti passaggi:
		\begin{enumerate}
			\item in primo luogo si inverte opportunamente l'equazione del sistema in modo da rendere l'$n$-esima derivata dell'uscita come una funzione delle sue derivate di ordine inferiore e dell'ingresso secondo un'espressione del tipo
			\[ \frac{d^n y}{dt^n} = \varphi \left( \frac{d^{n-1}y}{dt^{n-1}}, \dots, \frac{dy}{dt}, y, u \right)  \]
			\begin{nota}
				In generale l'ingresso $u$ può essere anche un vettore, quindi un insieme di valori.
			\end{nota}
			
			\item è ora possibile determinare le variabili di stato $x_i$ del sistema; in particolare la prima ($x_1$) la si impone coincidente all'uscita $y$ del sistema, mentre la seconda ($x_2$) alla derivata prima del sistema e cosi proseguendo:
			\[ x_1 = y \qquad,\quad x_2 = \dot y = \frac{dy}{dt} \qquad, \quad x_3 = \ddot y = \frac{dy^2}{dt^2} \qquad, \quad \dots \quad x_n = \frac{d^{n-1}y}{dt^{n-1}} \]
			
			\item per proseguire si deriva ogni variabile di stato nel tempo, osservando in maniera generale che $\dot x_{i} = x_{i+1}$, infatti:
			\[ \dot x_1 = \frac{dy}{dt} = x_2 \quad, \quad \dot x_2 = \frac d {dt} \frac{dy}{dt} = \frac{d^2y}{dt^2} = x_3 \quad \dots \quad \dot x_n = \frac{d^n y}{dt^n} =\varphi \left( x_n, \dots, x_2,x_1, u \right) \]
			Iterando questo processo (per cui $\dot x_i = x_{i+1}$) fino all'$n$-esima variabile di stato, si osserva che la derivata di quest'ultima è uguale alla funzione $\varphi$ descritta al punto 1 che, per quanto visto nel punto 2, può essere riscritta in funzione delle sole variabili di stato $x_i$ ora;
			
			\item a questo punto si osserva che da un'unica equazione differenziale di ordine $n$ si sono determinate $n$ equazioni differenziali del primo ordine del tipo $\dot x_n = x_{n+1}$ che possono essere \textit{semplicemente risolte} per integrazione;
			
			\item per completare la descrizione in forma di stato del sistema è necessario dunque determinare la trasformazione d'uscita che, per come assunto nel punto 2, coincide di fatto con la prima variabile di stato:
			\[ \textrm{trasformazione d'uscita: } \qquad y = x_1 \]
		\end{enumerate}
		
		\begin{esempio}{: applicazione del metodo generale per scrivere in forma di stato un sistema massa-molla-smorzatore}
			Un sistema massa-molla-smorzatore, mostrato in figura che segue, è un sistema dinamico caratterizzato dall'equazione differenziale
			\[ m\ddot s + c\dot s + ks = F \]
			dove $s$ è la coordinata dello spostamento della massa $m$, $c$ è il coefficiente di smorzamento e $k$ la costante elastica della molla; $F$ in questo caso rappresenta la forza applicata sulla massa.
			
			\begin{center}
				\tikzfig{Immagini/smorzatore}
			\end{center}
			
			Conoscendo la forza $F$ applicata al sistema (e dunque essa coincide con il nostro ingresso $u$) e volendo studiare lo spostamento $s$ del sistema (ossia l'uscita del sistema), è possibile risolvere il problema utilizzando la scrittura in forma di stato utilizzando il metodo appena descritto:
			\begin{enumerate}
				\item scrivendo l'equazione differenziale in funzione degli ingressi e delle uscite, essa risulta valere $m \ddot y + c\dot y + ky = u$; tramite inversione della relazione è possibile scrivere esplicitamente la derivata seconda dell'uscita come
				\[ \ddot y = - \frac c m \dot y - \frac k m y + \frac u m  \]
				
				\item essendo l'equazione differenziale di partenza del secondo ordine, è necessario scrivere le due variabili di stato del sistema che sono
				\[ x_1 = y = s \qquad x_2 = \dot y = \dot s \]
				
				\item a questo punto per determinare il sistema delle equazioni di stato è necessario derivare ogni variabile di stato nel tempo; la prima porta alla soluzione banale $\dot x_1 = x_2$, mentre la seconda risulta essere coincidente alla funzione di $\dot y,y,u$ determinata al punto 1 del metodo risolutivo:
				\[ \dot x_2 = \ddot y = - \frac c m x_2 - \frac k m x_1 + \frac u m \]
				E' possibile osservare come, a differenza del punto 1, in questo caso l'uscita (e la sua derivata) siano state sostituite dalle apposite variabili di stato.
				
				\vspace{2mm}
				
				A questo punto il \textbf{sistema delle equazioni di stato} è composto dalle relazioni
				\[  \begin{cases}
					\dot x_1 = x_2 \\ \dot x_2 = - \frac c m x_2 - \frac k m x_1 + \frac u m
				\end{cases} \]				
			\end{enumerate}
			Per completare la descrizione del problema nella rappresentazione di stato sarebbe necessario scrivere la trasformazione d'uscita che in questo caso coincide con la relazione
			\[  y = s = x_1 \]
			Tuttavia per altri problemi potrebbe essere necessario considerare per esempio la velocità $\dot s$ della massa (oppure l'accelerazione $\ddot s$), cambiando dunque la trasformazione d'uscita ad una relazione $y = \dot s = x_2$.
			
			\paragraph{Rappresentazione matriciale} Osservando il sistema delle equazioni di stato e la trasformazione d'uscita è possibile osservare come tutte le relazioni caratteristiche siano lineari rispetto a ingressi, uscite e variabili di stato; questo dunque permette di affermare che il sistema è lineare le cui matrici che rendono verificate l'equazione \ref{eq:rapp-matriciale} (pag. \pageref{eq:rapp-matriciale}) sono
			\[ A = \begin{bmatrix}
				0 & 1 \\ -k/m & - c/m
			\end{bmatrix} \qquad B = \begin{bmatrix}
				0 \\ -1/m
			\end{bmatrix} \qquad C = \begin{bmatrix}
				1 & 0
			\end{bmatrix} \qquad D = \begin{bmatrix}
				0
			\end{bmatrix} \]
		\end{esempio}
	
	\subsection{Sistemi a tempo discreto}
		Analizzare sistemi dinamici a tempo discreto richiede di utilizzare degli accorgimenti particolari. Infatti il metodo generale appena mostrato può essere considerato valido solamente se è possibile applicare il concetto di derivata al modello matematico che caratterizza il sistema. Per sistemi a tempo discreto questo non può avvenire (non essendo il tempo continuo, non è possibile calcolare la derivata come rapporto incrementale) e per questo si ricorre all'utilizzo delle \textbf{equazioni di stato alle differenze finite}
		\[ x(k+1) = f\Big(x(k),u(k), k\Big)  \]
		dove $k$ è un generico istante di tempo discreto. Per analogia è possibile scrivere le \textbf{trasformazioni d'uscita} utilizzando gli accorgimenti appena visti per rendere efficace la rappresentazione nel tempo discreto:
		\[ y(k) = g\Big(x(k), u(k), k\Big)  \]
		
		Anche in questo caso se i sistemi risultano essere lineari è possibile utilizzare la rappresentazione matriciale esposta nell'equazione \ref{eq:rapp-matriciale} (pag. \pageref{eq:rapp-matriciale}).
	
	\subsection{Sistemi dinamici nel dominio del tempo}
		Con la descrizione dei sistemi nello spazio di stato (pag. \pageref{sec:intro:spaziostato}) si è arrivato a descrivere i sistemi dinamici nel dominio continuo del tempo tramite delle equazioni di stato che permettevano di esprimere le derivate delle variabili di stato come dipendenti dalle grandezze stesse, oltre che dagli ingressi e dal tempo:
		\[ \dot x = f\Big(x(t), u(t), t\Big)\]
		
		\figuratikz{6}{1}{duecarrelli}{schema esemplificativo di due carrelli collegati tramite delle molle.}{duecarrelli}
		
		A pagina \pageref{sec:intro:metodogenerale} è stato mostrato un metodo generale per ricavare le equazioni di stato di un sistema, tuttavia si può dimostrare che tale rappresentazione non è mai unica, ma arbitraria, e la scelta delle variabili di stato può \textit{complicare} o \textit{semplificare} la rappresentazione matematica del modello. Considerando il sistema di due carrelli mutuamente collegati tramite delle molle (figura \ref{duecarrelli}), allora il sistema di equazioni fisico che lo modella è rappresentato dalle relazioni
		\[\begin{cases}
			m_1 \ddot s_1 + k_1s_1 + k_2(s_2-s_1) = 0 \\
			m_2\ddot s_2 + k_2(s_2-s1)=F
		\end{cases}\]
		A questo punto è possibile osservare come scegliendo in maniera diversa le variabili di stato, la rappresentazione di tale dominio può diventare più o meno complessa:
		\begin{itemize}
			\item considerando come coordinate le posizioni assolute $s_1$ ed $s_2$ delle due masse, individuando come variabili di stato $x_1 = s_1$, $x_2 = \dot s_1$, $x_3 = s_2$ e $x_4 = \dot s_2$ è possibile scrivere il sistema in spazio di stato tramite le relazioni
			\[ \begin{cases}
				\dot x_1 = x_2 \\ \dot x_2 = \frac 1 {m_1} (-k_1x_1-k_2x_3 + k_2x_1) \\
				\dot x_3 = x_4 \\ \dot x_4 = \frac 1 {m_2} (-k_2x_3 + k_2x_4 + u) \\
			\end{cases} \]
			\item scegliendo di rappresentare il sistema invece tramite la posizione assoluta $x_1$ della prima massa e la distanza relativa $\Delta$ tra $m_2$ e $m_1$ a cui sono associate le variabili di stato $x_1 = s_1$, $x_2 = \dot s_1$, $x_3 = \Delta$ e $x_4 = \dot \Delta$, procedendo alla scrittura del sistema in spazio di stato si ottiene:
			\[\begin{cases}
				\dot x_1 = x_2 \\
				\dot x_2 = \frac 1{m_1} \big(-k_1x_1+k_2x_3\big) \\
				\dot x_3 = x_4 \\
				\dot x_4 = \frac 1 {m_2} \left[\frac{m_2}{m_1}k_1x_1 + \left(-\frac{m_2}{m_1}k_2-k_2\right)x_3+u´\right]
			\end{cases}\]
		\end{itemize}
		Si osserva dunque che la prima scelta delle variabili di stato permette di ricavare una descrizione in spazio di stato che risulta essere più \textit{semplice} ed \textit{immediata}, mentre la seconda descrizione presenta delle equazioni differenziali più \textit{complesse} e \textit{lunghe}.
		\begin{osservazione}
			Nonostante le equazioni differenziali che descrivono il sistema per le due diverse scelte di variabili di stato siano diverse, esse tuttavia condividono delle proprietà cosiddette \textbf{\textit{strutturali}} che sono indipendenti dalla rappresentazione che si decide di utilizzare.
		\end{osservazione}
		
		\paragraph{Ordine di un sistema} In generale il numero di variabili di stato necessarie alla descrizione di un sistema dinamico (associate di fatto all'ordine delle equazioni differenziali) non sono una quantità fissa ma dipendono strettamente dal grado di complessità che si vuole utilizzare per descrivere il problema stesso.
		
		Facendo riferimento all'esempio dei due carrelli mutuamente collegati da una molla (fig. \ref{duecarrelli}) se si considera che il collegamento tra $m_1$ ed $m_2$ è molto più rigido rispetto al primo carrello e telaio, ossia se si verifica che $k_2\gg k_1$, allora è possibile \textit{semplificare} il modello ad un'unico carrello di massa equivalente $m_1+m_2$ collegato a telaio (figura \ref{duecarrelli-c}).
		
		\figuratikz{6}{1}{duecarrelli-c}{semplificazione del sistema in figura \ref{duecarrelli} nel caso in cui la molla $k_2$ sia molto più rigida della molla $k_1$.}{duecarrelli-c}
		
		In questa nuova configurazione si può osservare che il numero di variabili di stato scende da 4 a 2 (in quanto si ha una sola equazione differenziale del secondo ordine), tuttavia questo sistema presenterà solamente delle soluzioni approssimate rispetto al caso più complesso descritto in precedenza.
		
		\begin{concetto}
			In generale fissata la complessità del problema, il numero delle variabili di stato rimane sempre costante.
		\end{concetto}
	
		Esistono tuttavia dei sistemi dinamici \textit{speciali} che presentano un numero infinito di variabili di stato, e in particolare tra essi osserviamo:
		\begin{itemize}
			\item i sistemi descritti da equazioni differenziali alle derivate parziali;
			\item i \textbf{sistemi a ritardo di tempo} la cui trasformazione d'uscita è una \textit{traslazione nel tempo} dell'ingresso (eventualmente modificato) del tipo
			\[  y(t) = u(t-\tau) \]
		\end{itemize}
		
		
\section{Movimento di equilibrio}
	
	\begin{concetto}
		Dato un sistema rappresentato nella sua forma di stato e il valore dello stato $x_0$ al tempo $t_0$ è possibile indicare il \textbf{movimento d'uscita} $y(t)$ e il \textbf{movimento di stato} $x(t)$ come le grandezze che rappresentano le soluzioni delle equazioni differenziali che caratterizzano il sistema stesso.
	\end{concetto}
	In particolare il movimento di stato $x(t)$ si ricava per integrazione dell'equazione di stato $\dot x = f(x,u)$; nota tale funzione è dunque possibile calcolare immediatamente, mediante la trasformazione d'uscita, la funzione $y(t)$.
	
	\begin{nota}
		Un'osservazione che permetterà di semplificare l'analisi del problema si basa sul fatto che se il sistema è tempo invariante, allora i movimenti di stato e uscita non dipendono dalla scelta dell'istante $t_0$, ossia dal tempo di \textit{origine} del riferimento temporale.
	\end{nota}
	
	\begin{concetto} \label{conc:intro:movequilibrio}
		Studiando la dinamica di un sistema del quale si impone un'ingresso $u$ costante fissato al valore $\overline u$ e osservando che lo stato (e dunque l'uscita) risulta anch'essa stabilizzarsi ad un valore stazionario, allora quello che si determina è il \textbf{movimento di equilibrio} dello stato (uscita) del sistema stesso.
		
		Un movimento $\overline x$ per essere di equilibrio deve dunque essere tale da verificare la relazione
		\[ \dot{\overline x} = f\left(\overline x(t), \overline u\right) = 0 \]
	\end{concetto}
	
	\subsection{Movimento di equilibrio per sistemi lineari} 
		Per semplificare la ricerca del movimento di equilibrio per particolari sistemi, si fa ora riferimento alla classe dei sistemi lineari tempo invarianti che, come vedremo, saranno il tipo di sistema più \textit{facile} da analizzare. Per determinare il movimento di equilibrio dunque è sufficiente annullare il vettore $\dot x$ della rappresentazione matriciale (eq. \ref{eq:rapp-matriciale}):
		\[ 0 = Ax + Bu \qquad \Rightarrow \quad y = Cx + Du\]
		Il movimento di equilibrio dello stato $\overline x$ si può dunque determinare per inversione di tale espressione e, di conseguenza, è anche possibile determinare il movimento di equilibrio dell'uscita $\overline y$:
		\begin{equation}
			\overline x = -A ^{-1}B\overline u \qquad \Rightarrow\quad \overline y = \big(-CA^{-1}B + D\big)\overline u
		\end{equation}
		
		Da questa formulazione è possibile osservare che il l'equilibrio di un sistema lineare tempo invariante esiste solamente se la matrice di stato $A$ è invertibile, ossia se $\det(A)\neq 0$. Se tale condizione risulta essere verificata allora il punto di equilibrio (fissato l'ingresso costante $\overline u$) esiste ed è unico. Se si verificasse che $\det(A) = 0$ allora è possibile che:
		\begin{itemize}
			\item non ci siano soluzioni, ossia non esiste di fatto un equilibrio per il sistema;
			\item ci sono infiniti punti di equilibrio per il sistema.
		\end{itemize}
	
		\begin{esempio}{: movimento di equilibrio}
			Si consideri una massa $m$ \textit{tirata} da una forza $F$ (coincidente con l'ingresso $u$ del sistema). Tale sistema risulta essere dinamico in quanto l'equazione differenziale che governa il problema risulta essere $m\ddots s = F$ (dove $s$ è la coordinata di posizione della massa). Tale sistema può essere rappresentato in spazio di stato considerando come variabili di stato $x_1 = s$ e $x_2 = \dot s$ che permette di ricavare le equazioni differenziali
			\[ \dot x_1 = x_2 \qquad \textrm e \qquad \dot x_2 = \frac F m = \frac u m \]
			Nel caso in cui considerassimo di voler conoscere solamente come uscita la posizione $y = s$ della massa, si può classificare il sistema come SISO; osservando che lo stesso è anche lineare e tempo invariante nel dominio del tempo è possibile rappresentare il sistema con la notazione matriciale di matrici
			\[ A = \matrice{0 & 1 \\ 0 & 0} \qquad B = \matrice{0 \\ 1/m} \qquad C = \matrice{1 & 0} \qquad D = \matrice 0 \]
			
			Calcolando il determinate della matrice $A$ si osserva che esso è nullo: questo significa che l'equilibrio o non esiste o ne esistono infiniti (ma sicuramente non ne esiste uno e uno solo). Per poter capire di che tipo di equilibrio si tratta è dunque necessario riscrivere le equazioni di stato imponendo che le derivate delle variabili di stato $\dot x_i$ siano nulle: cosi favendo è possibile determinare i movimenti di equilibrio per il sistema
			\[\begin{cases}
				0 = \overline x_2 \\ 0 = \frac 1 m \overline u
			\end{cases} \qquad \Rightarrow\quad \overline x_2 = \dot s = 0 \quad \textrm e \quad \overline u = F = 0\]
			Dal sistema di osserva dunque che si ha un movimento di equilibrio solamente se l'ingresso $\overline u$ coincide con una forza nulla; in questo caso i movimenti di equilibrio sono infiniti (per ogni possibile velocità $\dot s$ e dunque posizione). \\
			Nel caso contrario in cui $\overline u$ non fosse un ingresso costante nullo il sistema delle equazioni di stato non ammetterebbe soluzione e quindi non si avrebbe alcun equilibrio.			
		\end{esempio}
		\begin{osservazione}
			Per i sistemi lineari, come appena visto, è sempre possibile effettuare delle considerazioni matematiche per capire se esiste una posizione di equilibrio, e in particolare si osserva che esso o non esiste, o esiste (ed è unico) oppure esiste e ce ne sono infiniti.
			
			Per quanto riguarda invece sistemi non lineari questo non è vero in generale, e non sono presenti dei \textit{metodi standard} per poter determinare la natura del movimento di equilibrio. Inoltre per tali sistemi può anche succedere che la posizione di equilibrio sia multipla (con molteplicità definita) e non solamente unitaria.
		\end{osservazione}		
		
	\subsection{Formula di Lagrange}
		Per calcolare il movimento di equilibrio di sistemi non lineari non esiste uno strumento analitico che risolve il problema in maniera del tutto generale, e dunque spesso è complesso analizzare tale tipi di sistemi; al contrario invece per sistemi lineari è possibile utilizzare la formula di Lagrange che permette di determinare in maniera esplicita il movimento di equilibrio del sistema.
		
		\begin{concetto}
			La \textbf{formula di Lagrange} permette di esprimere il movimento di stato $x(t)$ e la relativa uscita $y(t)$ nel tempo per qualsiasi ingresso e stato iniziale $x_0$ per un sistema lineare utilizzando le equazioni
			\begin{equation} \label{eq:intro:lagrange}
			\begin{aligned} 
				x(t) & = e^{At} x_0 + \int_0^t e^{A(t-\tau)} B u(\tau)\, d\tau \\
				y(t) & = Cx(t) + Du(t) = C e^{At} x_0 + C\int_0^t e^{A(t-\tau)} B u(\tau)\, d\tau + D u(t) \\
			\end{aligned}
			\end{equation}
		\end{concetto}
		Nell'equazione \ref{eq:intro:lagrange} è possibile osservare la presenza della \textbf{matrice esponenziale} (o di transizione) $e^{At}$ che è definita tramite uno sviluppo in serie di Taylor (in quanto è \textit{difficile} fare l'esponenziale di una matrice) tramite l'espressione
		\begin{equation}
			e^{At} = \sum_{k=0}^\infty \frac{(At)^k}{k!} = I + At + \frac{A^2t^2}{2!} + \frac{A^3t^3}{3!} + \dots 
		\end{equation}
		
		\begin{osservazione}
			Il movimento di stato $x(t)$ e di uscita $y(t)$ dipende sia dalla condizioni iniziali (ossia dallo stato $x_0$ al tempo $t_0 = 0$) che dalla storia degli ingressi $u$ in tutto l'intervallo di tempo compreso tra $t_0$ e il tempo rispetto al quale si vuole conoscere stato/uscita.
		\end{osservazione}
	
		Osservando l'equazione \ref{eq:intro:lagrange} è anche possibile osservare come i movimenti $x(t),y(t)$ possano essere \textit{scomposti} in due contributi indipendenti: quello del \textbf{movimento libero} $x_l$ del sistema, dipendente solamente dalle condizioni iniziali (ossia da $x_0$), e dal \textbf{movimento forzato} $x_f$ dipendente solamente dall'ingresso variante nel tempo (la \textit{parte integrale} dell'equazione). Facendo riferimento al movimento di stato la parte di movimento libero e forzato è descritto dalle relazioni:
		\[ x_l(t) = e^{At} x_0 \qquad x_f(t) = \int_0^t e^{A(t-\tau)} B u(\tau)\, d\tau  \]
		
	\subsection{Sovrapposizione degli effetti}
		\begin{concetto}
			Per sistemi dinamici lineari vige il cosiddetto \textbf{principio di sovrapposizione degli effetti} per il quale:
			\begin{itemize}
				\item il movimento libero dipende linearmente dalle condizioni iniziali, ossia considerando una situazione $x_0$ data dalla somma di due condizioni $\alpha x_0'+\beta x_0''$ (con $\alpha,\beta\in \mathds R$ coefficienti costanti), allora si verifica che
				\[ x_l = \alpha x_l' + \beta x_l'' \]
				
				\item il movimento forzato dipende linearmente dall'ingresso $u(t)$, ossia dati due ingressi $u'(t)$ e $u''(t)$ che generano l'ingresso $u(t)$ secondo la relazione lineare $\alpha u'(t) + \beta u''(t)$, allora il movimento forzato complessivo varrà
				\[ x_f(t) = \alpha x_f'(t) + \beta x_f''(t) \]				
			\end{itemize}
		\end{concetto}
		Questo principio è estremamente comodo in quanto se è possibile scomporre l'ingresso $u(t)$ in una combinazione lineare di ingressi \textit{più semplici}, allora è possibile studiare l'uscita del sistema come combinazione lineare delle \textit{uscite semplici} associate. Questo principio è inoltre molto comodo per studiare sistemi multi-ingresso (chiaramente solo se essi sono lineari!) in quanto per determinare l'uscita complessiva è sufficiente considerare la somma di ogni ingresso calcolato singolarmente.		
		
	\subsection{Linearizzazione di sistemi non lineari} \label{sec:intro:linearizzazione}
		Fino ad ora si è principalmente discusso la determinazione del movimento di equilibrio per sistemi lineari (per i quali è infatti associato un metodo \textit{standard} di risoluzione del problema), tuttavia nella realtà la maggior parte dei sistemi dinamici è fortemente non lineare. Tuttavia, utilizzando al scomposizione in serie di Taylor (troncata al primo ordine), ogni sistema non lineare può essere approssimato, nell'intorno di un punto specifico, con un suo equivalente linearizzato.
		
		\paragraph{Richiamo sulla linearizzazione tramite la serie di Taylor} Data una funzione generica $f$ che lega la variabile dipendente $y$ con quella indipendente $u$, ossia tale che $y = f(u)$, scelto un punto \textit{fisso} $\overline u$ nel dominio della funzione è possibile linearizzare la funzione $f$ nell'intorno di tale punto. In altre parole per ogni ingresso $u$ prossimo ad $\overline u$, ossia descritto da una relazione del tipo $u = \overline u + \delta u$ con $\delta u$ sufficientemente piccolo, è possibile pensare che la relazione che lega l'uscita con l'ingresso sia lineare. In particolare al punto $\overline u$ è associata l'uscita $\overline y = f\big(\overline u\big)$ e dunque applicando la serie di Taylor è possibile verificare la relazione tra la variazione $\delta y$ e $\delta u$:
		\begin{equation}\label{eq:intro:taylor}
			f\big(\overline u + \delta u \big) = \overline y + \delta y \xrightarrow{\textrm{Taylor}} f\big(\overline u\big) + \left. \pd f u \right|_{\overline u} \delta u \qquad \Rightarrow \quad \delta y = \left. \pd f u \right|_{\overline u} \delta u 
		\end{equation}
		In altre parole si osserva che la variazione dell'uscita $\delta y$ rispetto al valore nominale $\overline y$ è proporzionale alla variazione $\delta u$ dell'ingresso secondo un coefficiente pari alla \textit{pendenza} di $f$ nel punto di valutazione $\overline u$.
		
		\paragraph{Linearizzazione della rappresentazione in spazio di stato} Un sistema dinamico rappresentato in spazio di stato è determinato dalle equazioni di stato $\dot x = f(x,u)$ e dalla trasformazioni d'uscita $y = g(x,u)$; scelte dunque delle condizioni iniziali per lo stato $\overline x_0$ e l'ingresso $\overline u$ è dunque possibile determinare il movimento di equilibrio delle grandezze $\overline x,\overline y$ (pag. \pageref{conc:intro:movequilibrio}). A questo punto per linearizzare il sistema nell'intorno della condizione di equilibrio è sufficiente applicare la linearizzazione di Taylor (eq. \ref{eq:intro:taylor}) sia nell'intorno dell'ingresso $\overline u$ (ossia per $u = \overline u + \delta u$ con $\delta u$ sufficientemente piccolo), sia nell'intorno dello stato $\overline x$ (associato a $x = \overline x + \delta x$).
		
		Procedendo alla linearizzazione della rappresentazione in spazio di stato del sistema si arriva dunque al seguente risultato:
		\[ \begin{cases}
			\dot{\overline x} + \delta \dot x = f\big(\overline x + \delta x,\overline u + \delta u\big) \approx f\big(\overline x,\overline u\big) + \left. \pd f x \right|_{\overline x,\overline u} \delta x + \left. \pd f u \right|_{\overline x,\overline u}\delta u \\
			\overline y + \delta y = g\big(\overline x + \delta x,\overline u + \delta u\big) \approx g\big(\overline x,\overline u\big) + \left. \pd g x \right|_{\overline x,\overline u} \delta x + \left. \pd g u \right|_{\overline x,\overline u}\delta u \\
		\end{cases} \]
		Tramite questo sistema è possibile capire come variano le derivate delle grandezze di stato $\delta \dot x$ e uscita $\delta y$ nell'intorno del punto di equilibrio $\overline u, \overline x$ per variazioni $\delta u,\delta x$ di ingresso e stato; in particolare è possibile ricavare le matrici rappresentative del sistema linearizzato nell'intorno di tale punto come
		\begin{equation}
			A = \left. \pd f x \right|_{\overline x,\overline u} \qquad B = \left. \pd f u \right|_{\overline x,\overline u} \qquad C = \left. \pd g x \right|_{\overline x,\overline u} \qquad D = \left. \pd gu \right|_{\overline x,\overline u}
		\end{equation}
		
		Questo modello risulta essere tempo invariante fintanto che i termini $\overline x,\overline u$ rimangono costanti (in quanto non cambia il \textit{punto} di valutazione della derivata, e dunque le matrici sono a coefficienti fissi), ossia sono associati ad un movimento di equilibrio del sistema. Se invece il movimento non è di equilibrio allora è possibile mantenere il sistema linearizzato tuttavia introducendo la varianza nel tempo delle matrici $A,B,C,D$ associata allo spostamento di $\overline x,\overline u$ dipendente dal tempo $t$.
	