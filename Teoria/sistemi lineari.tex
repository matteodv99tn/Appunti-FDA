\chapter{Analisi di sistemi dinamici lineari tempo invarianti nel dominio di Laplace}
	A pagina \pageref{eq:rapp-matriciale} è stato mostrato come, nel dominio del tempo, la rappresentazione in spazio di stato di un sistema lineare tempo invariante possa essere descritta tramite una notazione matriciale in cui le equazioni di stato assumono una forma $\dot x = Ax+Bu$, mentre le trasformazioni d'uscita diventano $y = Cx+ Du$.
	
	A questo punto per procedere con l'analisi di questo tipo di sistemi è possibile effettuare una trasformazione nel dominio di Laplace, il che si riduce a trasformare completamente la rappresentazione di stato del sistema:
	\[\trasf{\ \begin{cases}
		\dot x = Ax + Bu \\ y = Cx+Du
		\end{cases}} \qquad \Rightarrow\quad \begin{cases}
		\trasf{\dot x(t)} = A\trasf{x(t)} + B\trasf{u(t)} \\
		\trasf{y(t)} = C\trasf{x(t)} + D\trasf{u(t)} 
	\end{cases}\]
	
	Sfruttando a questo punto la proprietà della trasformata della derivata di una funzione per la quale $\trasf{\dot x} = sX(s) - x_0$, allora la rappresentazione in forma di stato rispetto al dominio di Laplace può essere espressa come
	\begin{equation} \label{eq:lti:statolaplace}
		\begin{cases}
			sX(s) - x_0 = AX(s) + BU(s) \\ Y(s) = CX(s) + DU(s)
		\end{cases}
	\end{equation}
	
	\begin{concetto}
		Un \textbf{sistema lineare tempo invariante} può sempre essere descritto sia nel dominio del tempo che nel dominio della variabile di Laplace secondo una notazione matriciale della sua rappresentazione di stato, e nel caso di analisi tramite la teoria del controllo classico tale rappresentazione è mostrata in equazione \ref{eq:lti:statolaplace} (dove in particolare $x_0$ rappresenta lo stato del sistema al tempo $t=0$). \\ Invertendo opportunamente l'equazione di stato e la trasformata di uscita è dunque possibile stabilire il \textbf{movimento di stato} e \textbf{uscita} di un sistema lineare tempo invariante tramite la notazione
		\begin{equation} \label{eq:lti:movimenti}
		\begin{aligned}
			X & = \big(sI-A\big)^{-1} x_0 + \big(sI-A\big)^{-1} BU \\
			Y & = C \big(sI-A\big)^{-1} x_0 + \Big(C\big(sI-A\big)^{-1}B + D\Big)U
		\end{aligned}
		\end{equation}	
	\end{concetto}
	\begin{nota}
		Considerare un sistema come lineare ci permette di utilizzare una rappresentazione di stato in forma matriciale, mentre l'invarianza del sistema permette di stabilire che i coefficienti numerici delle matrici $A,B,C,D$ siano costanti nel sistema (e non dipendano dunque dal tempo).
	\end{nota}
	\begin{nota}
		Nel passaggio dall'equazione \ref{eq:lti:statolaplace} all'equazione \ref{eq:lti:movimenti} si ha l'introduzione del termine $sI$, con $I$ matrice identità, per rendere \textit{confrontabili} le operazioni di somma tra coefficiente scalare $s$ e matrice $A$.
	\end{nota}

	Dall'equazione \ref{eq:lti:movimenti} è dunque possibile stabilire come nel dominio di Laplace sia più \textit{facile} stabilire il movimento di stato e uscita di un sistema, in quanto si tratta di risolvere delle equazioni algebriche in forma matriciale. In particolare al calcolo del movimento libero $ e^{At} x_0 $ è associato il calcolo della matrice $(sI-A)^{-1}$, mentre al calcolo del movimento forzato $\int_0^t e^{A(t-\tau)} B u(\tau)\, d\tau$ è associata l'operazione $(sI-A)^{-1}BU$.
	
	Il \textit{costo} di analizzare il sistema nel dominio di Laplace è che è necessario prima trasformare l'ingresso $u(t)$ e poi anti-trasformare l'uscita $Y(s)$ per poter \textit{visualizzare intuitivamente} il movimento della stessa.
	
\section{Analisi del movimento di stato e uscita} \label{sec:lti:studiomovimenti}
	Dall'equazione \ref{eq:lti:movimenti} è possibile osservare che per determinare i movimenti sia di stato che di uscita è necessario invertire la matrice $sI - A$; in particolare supponendo che la matrice $A$ (sempre quadrata di dimensioni pari all'ordine del sistema) sia composta da elementi $a_{ij}$, allora si può esprimere 
	\[ sI - A = \matrice{s - a_{11} & \dots & -a_{1n} \\ \vdots & \ddots \\ -a_{n1} & & s-a_{nn} }   \]
	
	A questo punto è necessario invertire tale relazione e per fare questo si deve calcolare il \textbf{polinomio caratteristico} della matrice pari a $\varphi(s) = \det(sI-A)$ e calcolare i \textbf{complementi algebrici} $k_{ij}(s)$ della matrice (che risulteranno essere dei polinomi nella variabile $s$ di grado massimo pari a $n-1$):
	\[\big(sI-A\big) ^{-1} = \frac 1 {\varphi(s)} \underbrace{\matrice{k_{11}(s) & \dots & k_{1n}(s) \\ \vdots & \ddots \\ k_{n1}(s) & & k_{nn}(s) }}_K \]
	
	\begin{richiamo}
		Il \textbf{complemento algebrico} $k_{ij}$ (anche detto \textbf{cofattore}) di una matrice quadrata $A$ è calcolato come il determinante della sotto-matrice ottenuta eliminando ad $A$ l'$i$-esima riga e la $j$-esima colonna. Tale coefficiente è moltiplicato per un valore $1$ se la somma $i+j$ è pari, mentre con un valore $-1$ se $i+j$ è dispari.
	\end{richiamo}
	Avendo espresso dunque il termine $(sI-A)^{-1}$ come $\frac 1 {\varphi(s)} K$, ossia come una matrice di polinomi $K$ divisa per il determinante di $sI-A$, è possibile riscrivere il termine $(sI-A)^{-1} B $ dell'equazione \ref{eq:lti:movimenti} come
	\[  \big(sI-A\big)^{-1} = \frac 1 {\varphi(s)} KB = \frac{W(s)}{\varphi(s)} \]
	Anche in questa espressione $W(s)$ rappresenta una matrice di polinomi di ordine massimo pari ad $n-1$ ottenuta come combinazione lineare dei coefficienti di $B$ della matrice dei polinomi di $K(s)$.
	
	Considerando infine il termine $C\big(sI-A\big)^{-1}B + D$, anche questo può essere espresso alla fine come una combinazione lineare di $K(s)$ ottenuta dalle matrici $C$ e $B$ in modo da ottenere una matrice polinomiale $M(s)$ tale da soddisfare
	\[ C\big(sI-A\big)^{-1}B + D = \frac 1 {\varphi(s)} M(s) + D \]
	
	Per praticità scegliendo un sistema dinamico SISO quello che si ottiene è che sia la matrice $M$ che la matrice $D$ risultano essere monodimensionali (ossia appartenenti all'insieme $\mathds R^{1\times 1} = \mathds R$): questo significa che il termine $C\big(sI-A\big)^{-1}B + D$ può essere ridotto ad un polinomio razionale il cui denominatore coincide con il determinante di $sI-A$:
	\[ C\big(sI-A\big)^{-1}B + D = \frac 1 {\varphi(s)} M(s) + D = \frac{N(s)}{\varphi(s)}  \]
	
	\begin{osservazione}
		Il polinomio associato al denominatore $\varphi(s)$ potrà sempre avere grado massimo pari $n$ (dove $n$ è l'ordine del sistema), mentre essendo i polinomi delle matrici $K,W,M$ associati ai complementi algebrici di calcolati partendo da delle sotto-matrici di $sI-A$, il logo grado massimo sarà necessariamente pari a $n-1$ (come già affermato in precedenza). A questo punto considerando quest'ultima relazione riportata per i sistemi SISO si può affermare che $N(s)$ sarà un polinomio di grado al più $n$: in particolare se $D=0$ sicuramente il grado è inferiore (o uguale) a $n-1$ (in quando deriva direttamente da $M(s)$), mentre se $D\neq 0$ può arrivare ad avere un grado pari a quello del denominatore.
	\end{osservazione}
	\begin{concetto}
		Lavorando con sistemi dinamici lineari tempo invarianti, le trasformate associate ai vari ingressi con cui si avrà a che fare avranno sempre la seguenti caratteristiche:
		\begin{itemize}
			\item saranno sempre delle trasformate razionali, ossia sempre esprimibili come un rapporto tra due polinomi:
			\[F(s) = \frac{N(s)}{D(s)} \qquad \textrm{con $N(s),D(s)$ polinomi}\]
			\item il grado del numeratore sarà sempre uguale o minore del grado del denominatore.
		\end{itemize}
	\end{concetto}
	
\section{Stabilità di un sistema}
	
	Dato un sistema dinamico (in questo caso non necessariamente lineare tempo invariante) descritto in forma di stato dalle relazioni $\dot x = f(x,u)$ e $y=g(x,u)$, allora noto lo stato $x_0$ al tempo iniziale e la \textit{storia} degli ingressi $u(t)$, effettuando il passaggio al dominio di Laplace è dunque possibile calcolare il movimento sia dello stato che dell'uscita secondo le espressioni riportate in figura \ref{eq:lti:movimenti}. A questo punto, potendo calcolare tali movimenti, si vuole analizzarne la rispettiva stabilità.
	
	\begin{concetto}
		La \textbf{stabilità} studia la differenza tra un \textbf{movimento nominale} $\hat x, \hat y$ e un \textbf{movimento perturbato} $\tilde x, \tilde y$. In particolare si parla di \textbf{stabilità interna} quando il confronto viene effettuato rispetto al movimento di stato, mentre si parla di \textbf{stabilità esterna} se riferito alle uscite:
		\[ \textrm{stabilità interna: } \|\tilde x(t) - \hat x(t) \| \qquad \textrm{stabilità esterna: } \|\tilde y(t) - \hat y(t) \| \]
	\end{concetto}
	
	La perturbazione del movimento perturbato può essere ottenuta come variazione sia delle condizioni iniziali $\tilde x_0\neq \hat x_0$, sia come variazione degli ingressi $\tilde u(t) \neq \hat u(t)$, tuttavia questo secondo caso generico lo si trascura in quanto è possibile modellare la \textit{storia} degli ingressi pregressi scegliendo un opportuno valore dello stato $\tilde x_0$ al tempo iniziale. In generale le perturbazioni sull'ingresso possono essere sempre ricondotte a perturbazioni sulle condizioni iniziali sullo stato $x_0$ del sistema stesso.
	
	\begin{concetto}
		Analizzando la stabilità di un movimento perturbando lo stato di un sistema permette di determinare 3 tipi di equilibri del moto perturbato rispetto a quello nominale, in particolare
		\begin{itemize}
			\item il movimento è \textbf{instabile} se il moto perturbato diverte da quello nominale ad un valore \textit{infinito};
			\item il movimento è \textbf{semplicemente stabile} se asintoticamente esso converge ad un valore diverso da quello nominale (tuttavia rimane sempre confinato in un intorno del valore perturbato);
			\item il movimento è detto \textbf{asintoticamente stabile} se il moto perturbato converge asintoticamente al valore del movimento nominale.
		\end{itemize}
	\end{concetto}
	
	La classificazione delle proprietà di stabilità del movimento dipende strettamente dal sistema dinamico che si vuole analizzare e dal modello di analisi utilizzato per lo stesso: per esempio un pendolo con attrito risulta essere asintoticamente stabile, mentre un pendolo senza attrito è semplicemente stabile.
	
	\begin{osservazione}
		La stabilità di un movimento è una proprietà locale, ossia solo alcuni movimenti sono stabili e solamente per alcune perturbazioni limitate rispetto allo stato iniziale nominale che si sta considerando. Questo permette di definire infatti la \textbf{regione di attrazione} come l'insieme delle condizioni iniziai per cui il movimento è asintoticamente stabile al valore nominale $\hat x_0$. Quando la regione di attrazione coincide con tutte le possibili condizioni iniziali, si parla allora di \textbf{stabilità asintotica globale}.
	\end{osservazione}
	
	\subsection{Stabilità del movimento per sistemi lineari tempo invarianti}
		Considerando ora il caso di sistemi lineari tempo invarianti, l'equazione \ref{eq:lti:movimenti} permette di descrivere completamente il movimento d'uscita $\|\tilde y(t) - \hat y(t) \|$ (e analogamente il movimento d'uscita). Considerando che per determinare la stabilità si considerano delle perturbazioni sullo stato del sistema e non sugli ingressi, allora è possibile affermare che $\tilde u(t) = \hat u(t)$ il cui risultato si rispecchia anche sulle trasformate $\tilde U(s) = \hat U(s)$. A questo punto è possibile calcolare la variazione tra uscita nominale e perturbata nel dominio di Laplace arrivando al risultato che
		\begin{equation} \label{eq:lti:deltauscita}
			\Delta Y(s) = \hat Y(s) - \tilde Y(s) = C \big(sI-A\big)^{-1}\big(\hat x_0 - \tilde x_0\big) = C\big(sI-A\big)^{-1} \Delta x_0
		\end{equation}
		\begin{concetto} \label{conc:lti:regionetotale}
			Dall'equazione \ref{eq:lti:deltauscita} è possibile osservare che la \textbf{stabilità del movimento d'uscita} di un sistema lineare tempo invariante è associata al \textbf{movimento libero} del sistema; si osserva infatti che la stabilità di questi sistemi non dipende dal particolare movimento considerato, ma assume valenza generale e dunque vale per ogni movimento del sistema.
		\end{concetto}
		Dall'equazione \ref{eq:lti:deltauscita} è possibile osservare che la perturbazione $\Delta x_0$ rappresenta solo un \textit{fattore di scala} della variazione dell'uscita $\Delta Y$, la cui proprietà di stabilità (instabile o asintoticamente/semplicemente stabile) dipende solamente dal termine $C\big(sI-A\big)^{-1}$ e non dalla perturbazione dello stato. Dimostrando dunque che il sistema è asintoticamente stabile, allora la regione di stabilità è globale.
		
		\begin{concetto}
			Lo studio del movimento di stato/uscita perturbato al fronte di cambiamenti/perturbazioni iniziali è equivalente, salvo alcune eccezioni che verranno discusse, allo studio del movimento tramite la risposta del sistema ad un impulso in ingresso.
		\end{concetto}
		Questa affermazione non può essere attualmente dimostrata (ma lo sarà nel seguito), e si basa sul fatto che la trasformata dell'impulso è unitaria per ogni valore del dominio di Laplace $s$. A questo punto per descrivere la stabilità è possibile utilizzare indipendentemente uno dei due metodi: studio della variazione dello stato iniziale o risposta all'impulso:
		\[\textrm{stabilità:} \qquad \Delta Y(s) = C\big(sI-A\big)^{-1} \Delta x_0 \quad \leftrightarrow \quad Y(s) = \Big(C\big(sI-A\big)^{-1}B + D\Big)\cancel{U(s)}\]
		
		In entrambi i casi è possibile osservare che sia la relazione $C\big(sI-A\big)^{-1}$ che $C\big(sI-A\big)^{-1}B + D$ possono essere descritti come un rapporto di un polinomi di numeratore rispettivamente $N(s)$ e $W(s)$ e denominatore uguale e pari a $\varphi(s) = \det(sI-A)$ (rispetto a come visto da pagina \pageref{sec:lti:studiomovimenti}).
		
		Dal punto di vista pratico è più \textit{conveniente} studiare la stabilità come risposta del sistema all'impulso piuttosto che analizzare una variazione dello stato iniziale. Infatti in questo secondo caso la variazione di uscita $\Delta Y$ dipende da $n$ condizioni iniziali coincidenti con l'ordine del sistema, mentre nel caso di risposta all'impulso unitario l'uscita è univocamente determinata dal prodotto matriciale
		\[ \underbrace{\Delta Y(s) = C\big(sI-A\big)^{-1} \Delta x_0}_{\substack{\textrm{1 uscita} \\ \textrm{$n$ condizioni iniziali} }} \qquad \leftrightarrow \qquad \underbrace{Y(s) = C\big(sI-A\big)^{-1}B + D}_{\substack{\textrm{1 uscita} \\ \textrm{condizione iniziale fissata} }}\]

\section{Criteri di stabilità}
	Nel concetto \ref{conc:lti:regionetotale} è affermato che la stabilità di un sistema lineare tempo invariante è una proprietà \textit{strutturale} del sistema stesso, ossia è indipendente dal movimento. A questo punto quello che si vuole stabilire è se, di fatto, il sistema è asintoticamente stabile.
	
	Studiando la risposta all'impulso $Y= C\big(sI-A\big)^{-1} B + D$ è possibile infatti osservare 3 possibili comportamenti del sistema:
	\begin{itemize}
		\item se l'uscita converge al valore nullo allora il \textbf{sistema} è \textbf{asintoticamente stabile};
		\item se l'uscita converge ad un valore reale non nullo, allora il sistema è \textbf{semplicemente stabile};
		\item se l'uscita diverge al valore $\pm \infty$ allora il sistema è detto \textbf{instabile}.
	\end{itemize}	
	
	Potendo scrivere la trasformata dell'uscita $Y(s)$ (per ingressi \textit{canonici}) come un rapporto polinomiale $N(s)/D(s)$, allora applicando il metodo di Heaviside (pag. \pageref{sec:class:heaviside}) è possibile esprimere tale movimento come una combinazione lineare di \textit{elementi più semplici}:
	\[ Y(s) = \frac{N(s)}{D(s)} = \frac A \dots + \frac B \dots + \dots \]
	A questo punto ipotizzando che la trasformata non presenti poli multipli (le radici del denominatore sono \textit{semplici}, non multiple)  e che gli stessi siano reali, allora i vari termini nel dominio del tempo sono associati a degli esponenziali del tipo $e^{-at}$, dove $a$ è il coefficiente costante dei polinomi a denominatore degli elementi semplici di $D(s)$. In particolare il termine $a$ rappresenta l'opposto dei poli della trasformata, e dunque si evince che se i poli sono positivi allora l'esponenziale tende a divergere, per poli nulli l'esponenziale diventa costante e dunque il sistema semplicemente stabile, mentre per poli negativi l'uscita converge al valore nullo e il sistema è asintoticamente stabile.
	\begin{esempio}{: poli e stabilità}
		Si consideri la trasformata $F(s)= \frac{3s^2 - 2 s - 2}{s(s+1)(s-2)} $ i cui poli sono $s=-1,0,2$; applicando la scomposizione di Heaviside è possibile osservare che
		\[ F(s) = \frac{3s^2 - 2 s - 2}{s(s+1)(s-2)}  = \frac 1 s+ \frac 1 {s+1} + \frac  1{s - 2}\]
		\[ \Rightarrow \qquad f(t) = \anti{F(s)} = e^{0t} + \scal (t) e^{-1t} \scal(t) + e^{2t}\scal(t) \]
		Considerando infatti il primo \textit{contributo elementare} pari a $\frac 1 s$ (con coefficiente $a = 0$) a cui è associata l'anti-trasformata $\cancel{e^{0t}} ^{=1} \scal(t)$, si osserva che per $t\rightarrow\infty$ il termine tende al valore unitario. Considerando ora il secondo termine elementare, ossia il polo reale negativo $s=-1$ (cui è associato il coefficiente $a= 1$), si osserva che la sua anti-trasformata $e^{-t}\scal(t)$, per $t\rightarrow \infty$, tende proprio al valore nullo. Al contrario il polo positivo in $s =2$ (coefficiente $a= -2$) presenta anti-trasformata pari a $e^{2t}\scal(t)$ che a tempo infinito diverge.		
	\end{esempio}
	
	Nel caso di poli complessi coniugati distinti, allora la scomposizione di Heaviside determina delle anti-trasformate del tipo $e^{-\sigma t} \sin(\omega t)$, ossia dei segnali (co)sinusoidali smorzati: anche in questo caso la convergenza è associata alla parte reale del polo e in particolare se essa è negativa il sistema è asintoticamente stabile, mentre se essa è positiva il sistema è instabile. Anche nel caso di poli multipli è possibile osservare la convergenza degli elementi in base al \textit{segno} della parte reale delle radici in quanto si osserva che
	\[ \anti{\frac 1 {(s+a)^n}} t^{n-1} e^{-at} \quad \begin{cases}
		\textrm{diverge se il polo è positivo ($a<0$)} \\
		\textrm{converge se il polo è negativo ($a>0$)} 
	\end{cases} \]	
	
	\begin{teorema}{stabilità di sistemi lineari tempo invarianti}  
		
		\texttt{Enunciato:}  { \itshape Dato  un sistema lineare tempo invariante la cui risposta all'impulso è caratterizzata dall'equazione
		\[ Y(s) = C \big(sI-A\big)^{-1} B + D = \frac{N(s)}{\det(sI-A)} = \frac{N(s)}{\varphi(s)} \]  \label{teor:lti:stabilita}
		allora il \textbf{sistema} è \textbf{asintoticamente stabile} se e solo se tutte i \textbf{poli} (radici di $\varphi(s)$) hanno \textbf{parte reale negativa}; il sistema è semplicemente stabile se esiste un solo polo (non multiplo) a parte reale nulla mentre se esiste anche un solo polo a parte reale positiva (o esistono poli a parte reale nulla multipli), il sistema è instabile.}
	\end{teorema}

	In pratica dunque l'analisi di stabilità (esterna) di un sistema lineare tempo invariante si pratica calcolando in primo luogo l'uscita $Y(s)$ come risposta all'impulso, ossia pari a $C \big(sI-A\big)^{-1} B + D$, e poi vi si calcolano i poli che lo compongono.
	
	\begin{esempio}{: stabilità in un sistema lineare tempo invariante} 
		Si consideri il sistema dinamico lineare tempo invariante la cui rappresentazione in forma di stato (nel dominio di Laplace) è dato dalle relazioni
		\[ \dot X= \matrice{-2 & 0 \\ 0 & 4} X + \matrice{1 \\ 1}U \qquad Y = \matrice{1 & 1} X + \matrice{0}U \]
		A questo punto per studiare la stabilità dell'uscita del sistema è sufficiente calcolare la risposta all'impulso dello stesso:
		\begin{align*}
			C\big(sI-A\big)^{-1} B + D & = \matrice{1 & 1} \frac 1 {(s+2)(s-4)} \matrice{s-4 &0 \\ 0 & s+2 }\matrice{1 \\ 1} \\
			& = \matrice{1 & 1} \frac 1 {(s+2)(s-4)} \matrice{s-4 \\ s+2} \\
			&= \frac{2s-2}{(s+2)(s-4)}
		\end{align*}
		Osservando il polinomio $\varphi(s) =(s+2)(s-4)$ a denominatore, si osserva che i suoi zeri (ossia i poli della trasformata dell'uscita $Y$) sono $s_1 = -2$ ed $s_2 = 4$: il primo è a parte reale negativa, e dunque compatibile con l'asintotica stabilità, tuttavia il secondo, essendo a parte reale positiva, determina l'instabilità del sistema dinamico.
	\end{esempio}
	
	\begin{osservazione}
		I poli del denominatore $D(s)$ della trasformata $Y$ di fatto sono associati agli zeri del determinante di $sI-A$, ossia coincidono con le radici del polinomio caratteristico della matrice di stato, o, per essere più precisi, i poli coincidono con gli \textbf{autovalori} della matrice di stato $A$. Va notato però che calcolare la stabilità dell'uscita di un sistema non è consigliato calcolare solamente gli autovalori di $A$: tale metodo infatti può portare a degli errori nell'applicare il teorema i stabilità. Infatti nel calcolo esplicito di $N(s)/D(s)$ è possibile incontrare delle \textit{cancellazioni critiche} tra elementi a numeratore e denominatore che rendono un sistema da instabile a asintoticamente stabile.
	\end{osservazione}
	Nel caso di sistemi di ordine elevato (maggiore di 3) spesso può risultare difficile calcolare i poli dell'uscita $Y(s)$ (e dunque sfruttare il teorema \ref{teor:lti:stabilita}): per questo si devono introdurre dei criteri alternativi per il calcolo della stabilità (indipendenti dal calcolo dei poli).
	
	\subsection{Tabella di Routh}
		Il metodo basato sulla tabella di Routh è un criterio di stabilità basato sull'analisi diretta del polinomio a denominatore della trasformata $Y(s)$ ed è particolarmente efficace quando la fattorizzazione dello stesso non è immediata. In generale il polinomio a denominatore $D(s)$ può essere espresso tramite dei coefficienti generici $d_i$ del tipo
		\[  D(s) = d_0s^n + d_1 s^{n-1} + \dots + d_{n-1}s + d_n \]
		
		\begin{teorema}{condizione di asintotica stabilità} 
			
			Condizione necessaria (ma non sufficiente) affinché un sistema risulti \textbf{asintoticamente stabile} è che tutti i coefficienti $d_i$ del polinomio che compongono il denominatore siano non nulli e di verso concorde. \label{teor:lti:asintotrouth}
		\end{teorema}
		In particolare per polinomi di grado $n=1,2$, tale condizione oltre ad essere necessaria è anche sufficiente. Per polinomi di ordine superiore ($n\geq 3$) la \textbf{condizione sufficiente} per avere asintotica stabilità è che tutti i coefficienti della \textbf{tabella di Routh} siano tutti non nulli e concordi in segno.
		
		\paragraph{Tabella di Routh} Dato un polinomio di grado $n$ (associato al denominatore di una trasformata razionale $Y(s)$), la \textbf{tabella di Routh} (il cui schema generico è mostrato in tabella \ref{tab:lti:routh}) derivante dalla stessa è una tabella di $n+1$ righe così costituite:
		\begin{itemize}
			\item la prima riga contiene i coefficienti $d_i$ con indice $i$ pari (in ordine crescente), mentre la seconda riga contiene i coefficienti di indice dispari;
			\item le $n-1$ righe restanti sono costruite ricorsivamente tramite la seguente relazione: noti i coefficienti di due righe contigue $h_i,k_i$, l'$i$-esimo elemento della riga a loro successiva $l_i$ è determinato dall'equazione
			\[ l_i = - \frac 1{k_1}\det \matrice{h_1 & h_{i+1} \\ k_1 & k_{i+1}} \]
		\end{itemize}
		Gli elementi delle prime due righe che sono necessarie per calcolare gli elementi \textit{discendenti} sono tutti da considerarsi come degli zeri.
		\begin{SCtable}[1][bht]
			\centering
			\begin{tabular}{r | c c c c| }
				prima riga & $d_0$ & $d_2$ & $d_4$ & $\dots$ \\
				seconda riga & $d_1$ & $d_3$ & $d_5$ & $\dots$ \\
				& $\vdots$ \\
				& $h_1$ & $h_2$ & $h_3$ & $\dots$ \\
				& $k_1$ & $k_2$ & $k_3$ & $\dots$ \\
				& $l_1$ & $l_2$ & $l_3$ & $\dots$ \\
			\end{tabular}
			\caption{schema di riferimento della tabella di Routh.} \label{tab:lti:routh}
		\end{SCtable}
		
		\begin{dimostrazione}
			Avendo introdotto il principio di funzionamento della tabella di Routh è ora possibile dimostrare come, per sistemi di ordine 2, la condizione necessaria di coefficienti $d_i$ non nulli concordi (teorema \ref{teor:lti:asintotrouth}) sia anche sufficiente. Considerando il polinomio $D(s) = d_0s^2 + d_1s + d$ composto da coefficienti $d_0,d_1,d_2$ concordi (non nulli), allora le prime due righe della tabella di Routh possono essere considerate nella matrice
			\[ \matrice{d_0 & d_2 \\ d_1 & 0} \]
			
			Essendo il polinomio di ordine 2, allora la tabella di Routh necessiterà solamente di un'altra riga i cui coefficienti $l_i$ possono essere calcolati come
			\[ l_1 = - \frac 1 {d_1}\det \matrice{d_0 & d_2 \\ d_1 & 0} = d_2 \qquad l_2 = - \frac 1 {d_1}\det \matrice{d_0 & 0 \\ d_1 & 0} = 0 \]
			Questo significa che la tabella di Routh presenta coefficienti
			\[ \matrice{d_0 & d_2 \\ d_1 & 0 \\ d_2 & 0} \]
			e dunque essendo $d_0,d_1,d_2$ (elementi della prima colonna della tabella di Routh) tutti concordi e non nulli (per ipotesi iniziale), allora si dimostra che ogni sistema dinamico di ordine 2 (con tale proprietà sui coefficienti) è asintoticamente stabile.
		
		\end{dimostrazione}

	\subsection{Autovalori della matrice di stato e poli di una trasformata}
		In precedenza si era affermato che i poli di una trasformata razionale $Y(s) = N(s)/D(s)$ erano  correlati agli autovalori della matrice di stato $A$ (in quando direttamente determinati dal polinomio caratteristico di tale matrice), tuttavia è necessario fare chiarezza sul considerare gli autovalori per determinare la stabilità o meno di un sistema.
		
		Considerando, per esempio, il sistema rappresentato in forma di stato (nel dominio di Laplace) dalle relazioni
		\[ \dot X= \matrice{0 & 0 \\ 0 & 0} X + \matrice{1 \\ 1}U \qquad Y = \matrice{1 & 1} X + \matrice{0}U \]
		e' possibile osservare che gli autovalori della matrice di stato $A$ sono coincidenti e pari a zero ($\lambda_1 = \lambda_2 = 0$): se tali valori coincidessero con i poli dell'uscita $Y(s)$, allora, per come visto nel teorema \ref{teor:lti:stabilita} (pag. \pageref{teor:lti:stabilita}), si dovrebbe concludere che il sistema è instabile. Tuttavia analizzando la risposta all'impulso si ottiene un risultato diverso, infatti:
		\begin{align*}
			C\big(sI-A\big)^{-1} B + D & = \matrice{1 & 1 } \frac 1 {s^{\cancel{2}}} \matrice{\cancel s & 0 \\ 0 & \cancel s} \matrice{1 \\ 1} + \matrice 0 \\
			& = \frac 1 s \matrice{1 & 1} \matrice{1 \\ 1} = \frac 2 s
		\end{align*}
		Infatti il denominatore dell'uscita $Y$ vale per l'appunto $D(s) = s$, e dunque per lo stesso criterio di stabilità essendo presente una sola radice nulla del denominatore, il sistema può essere considerato come semplicemente stabile.
		
		\begin{concetto}
			In generale è possibile utilizzare gli autovalori della matrice di stato per determinare la stabilità (o meno) di un sistema solamente se gli stessi sono \textit{regolari}, ossia e la loro molteplicità geometrica coincide con quella algebrica: negli altri casi non è possibile asserire alcuna proprietà di stabilità del sistema.
		\end{concetto}
		Per enunciare un criterio di stabilità basato sugli autovalori della matrice di stato analogo a quello visto per le radici di $D(s)$ occorrerebbe analizzare altre proprietà della matrice di stato stessa.
		
		\begin{concetto}
			Gli \textbf{autovalori} determinano di fatto la \textbf{stabilità interna} del sistema, mentre la risposta dell'uscita ad un impulso in ingresso permette di analizzare la \textbf{stabilità esterna} del sistema: in particolare i due movimenti possono essere \textit{diversi} per via della presenza di \textbf{\textit{parti nascoste}} del sistema dinamico che lo rendono \textit{irregolare}.
		\end{concetto}
		\begin{osservazione}
			Per quanto appena affermato, e osservando l'esempio riportato in calce al paragrafo, è possibile affermare che l'instabilità interna non determina necessariamente l'instabilità esterna: il sistema originario infatti era instabile internamente ma semplicemente stabile per quanto riguarda l'uscita.
		\end{osservazione}
		
		\begin{esempio}{: stabilità interna ed esterna}
			Si consideri il seguente sistema dinamico lineare tempo invariante rappresentato in forma di stato nel dominio di Laplace delle equazioni
			\[ \dot X= \matrice{1 & 1 \\ 0 & -3} X + \matrice{1 \\ 1}U \qquad Y = \matrice{0 & 1} X \]
			
			Essendo la matrice di stato $A$ triangolare allora i suoi autovalori coincidono con gli elementi diagonali e dunque sono pari a $\lambda_1 = 1$ e $\lambda_2 = -2$: applicando il teorema di stabilità essendo $\lambda_1$ un elemento a parte reale positiva, allora il movimento di stato (associato alla \textbf{stabilità interna}) è \textbf{instabile}. Al contrario analizzando la risposta all'impulso si può osservare la cancellazione di tale polo, infatti:
			\[ Y(s) = C \big(sI-A\big)^{-1}B = \frac{\cancel{s-1}}{\cancel{(s-1)}(s+2)} = \frac 1 {s+2} \] 
			La radice del denominatore è dunque unica e pari a $s_1 = -2$: utilizzando il teorema di stabilità si evince dunque che il \textbf{sistema} è \textbf{esternamente asintoticamente stabile}.
			
			\vspace{3mm}
			Considerando più nel dettaglio la struttura delle equazioni di stato si determina infatti che
			\[ \begin{cases}
				\dot x_1 = x_1 \\ \dot x_2 = x_1-2x_2 + u \\ y = x_1 + x_2
			\end{cases} \]
			\begin{center}
				\includegraphics[width=4cm]{sist-nonragg}
			\end{center}
			In questo caso si può affermare che il sistema non è completamente raggiungibile dall'ingresso $u$: gli autovalori della matrice di stato sono in quantità superiore dei poli dell'uscita che risponde all'impulso e dunque l'analisi di stabilità esterna può non coincidere con la stabilità esterna.
			
		\end{esempio}
	
	\subsection{Osservabilità di un sistema dinamico}
		Si consideri il sistema dinamico mostrato in figura \ref{sist-inoss} composto da due masse che possono scorrere sul piano. L'attuatore idraulico (o il sensore di elongazione) permettono dunque di determinare uno spostamento (o misurarlo rispettivamente) relativo tra le due masse $m_1,m_2$, ma non permettono di determinare la posizione assoluta delle stesse.	
	
		\figura{5}{3}{sist-inoss}{sistema composto da due carrelli in cui $m_1$ è collegato a telaio da una molla, mentre $m_2$ è collegato ad $m_1$ tramite una molla e un attuatore/sensore (evidenziato in giallo).}{sist-inoss}
		
		Questo è un esempio pratico di \textbf{sistema non completamente raggiungibile/osservabile}: analizzando la rappresentazione in forma di stato del sistema dinamico ci si accorge infatti che l'ordine del denominatore $D(s)$ è minore dell'ordine del sistema dinamico di partenza, il che implica che nel processo di analisi dell'impulso è stata commessa una cancellazione.
		
		\vspace{3mm}
		
		La sola ispezione delle equazioni di stato non sempre permette di individuare se il sistema è completamente raggiungibile o osservabile; per effettuare tale analisi è necessario ricorrere a strumenti quali:
		\begin{itemize}
			\item il confronto dell'ordine del polinomio a denominatore $D(s)$ con l'ordine del sistema (se il primo ha grado inferiore del secondo, allora sono state effettuate delle cancellazioni critiche);
			\item utilizzare dei test specifici di raggiungibilità ed osservabilità; tali metodi (che non verranno trattati) si basano sulla formulazione della matrice di raggiungibilità $R = f(A,B)$ e dalla matrice di osservabilità $O = f(A,C)$.
		\end{itemize}
		
		
		
		
		
		
		
		
		
	